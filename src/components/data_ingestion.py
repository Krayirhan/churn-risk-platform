# ============================================================================
# data_ingestion.py â€” Veri Alma ve Train/Test BÃ¶lme BileÅŸeni
# ============================================================================
# NEDEN BU DOSYA VAR?
#   ML pipeline'Ä±nÄ±n ilk adÄ±mÄ±: veriyi al ve train/test olarak bÃ¶l.
#   Ä°ki farklÄ± modda Ã§alÄ±ÅŸÄ±r:
#
#   MOD 1 â€” NOTEBOOK BRIDGE (VarsayÄ±lan):
#     Notebook Section 11'de export edilen telco_prepared_dataset.npz'yi yÃ¼kler.
#     Bu dosyada X_mat (preprocessed matris), y (hedef), X_pca_95 (PCA kÃ¼Ã§Ã¼ltÃ¼lmÃ¼ÅŸ)
#     zaten hazÄ±r durumda. Notebook tÃ¼m cleaning + FE + preprocessing'i yapmÄ±ÅŸ.
#
#   MOD 2 â€” RAW CSV FALLBACK:
#     Notebook Ã§alÄ±ÅŸtÄ±rÄ±lmamÄ±ÅŸsa veya .npz yoksa, ham CSV'den okur.
#     Bu durumda data_transformation.py'nin iÅŸi artar (cleaning + FE yapmasÄ± gerekir).
#
# Ã‡AÄžRILIÅž ÅžEKLÄ°:
#   train_pipeline.py â†’ DataIngestion().initiate() â†’ (X_train, X_test, y_train, y_test)
# ============================================================================

import os
import sys
import pandas as pd
from dataclasses import dataclass
from sklearn.model_selection import train_test_split

from src.exception import CustomException
from src.logger import logging
from src.utils.common import load_yaml, load_npz


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# KONFÄ°GÃœRASYON SINIFI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# @dataclass: __init__ yazmaya gerek kalmaz, sadece alan tanÄ±mla.
# TÃ¼m yollar config.yaml'dan okunur â†’ hardcoded yol SIFIR.

@dataclass
class DataIngestionConfig:
    """
    Veri alma sÃ¼recinin tÃ¼m ayarlarÄ±.
    __init__ iÃ§inde config.yaml okunur ve yollar buradan Ã§ekilir.
    """
    # Config dosyasÄ±nÄ± oku
    _cfg: dict = None

    def __post_init__(self):
        """
        @dataclass'Ä±n __init__ sonrasÄ±nda otomatik Ã§alÄ±ÅŸan hook'u.
        Config.yaml'Ä± yÃ¼kleyip dosya yollarÄ±nÄ± ayarlar.
        """
        self._cfg = load_yaml("configs/config.yaml")

        data_cfg = self._cfg.get("data", {})
        artifacts_cfg = self._cfg.get("artifacts", {})
        split_cfg = self._cfg.get("split", {})

        # --- Notebook artifact yollarÄ± ---
        # Notebook'un export ettiÄŸi .npz dosyasÄ±nÄ±n tam yolu
        self.notebook_artifacts_dir: str = data_cfg.get("notebook_artifacts_dir", "notebooks/artifacts")
        self.npz_filename: str = data_cfg.get("npz_filename", "telco_prepared_dataset.npz")
        self.npz_path: str = os.path.join(self.notebook_artifacts_dir, self.npz_filename)

        # --- Ham veri yolu (fallback) ---
        self.raw_data_path: str = data_cfg.get("raw_path", "data/raw/churn.csv")

        # --- Artifacts Ã§Ä±ktÄ± yollarÄ± ---
        self.artifacts_dir: str = artifacts_cfg.get("base_dir", "artifacts")
        self.train_data_path: str = artifacts_cfg.get("train_data_path", "artifacts/train.npz")
        self.test_data_path: str = artifacts_cfg.get("test_data_path", "artifacts/test.npz")

        # --- Split parametreleri ---
        self.test_size: float = split_cfg.get("test_size", 0.2)
        self.random_state: int = split_cfg.get("random_state", 42)
        self.stratify: bool = split_cfg.get("stratify", True)

        # --- Hedef sÃ¼tun adÄ± (raw CSV modu iÃ§in) ---
        self.target_col: str = self._cfg.get("target_col", "Churn")
        self.id_col: str = self._cfg.get("id_col", "customerID")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ANA SINIF
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class DataIngestion:
    """
    Veri alma ve train/test bÃ¶lme iÅŸlemlerini yÃ¼rÃ¼ten ana sÄ±nÄ±f.
    
    KullanÄ±m:
        ingestion = DataIngestion()
        X_train, X_test, y_train, y_test = ingestion.initiate()
    """

    def __init__(self):
        self.config = DataIngestionConfig()

    def _load_from_notebook_npz(self) -> tuple:
        """
        MOD 1: Notebook'un Ã¼rettiÄŸi .npz dosyasÄ±ndan veri yÃ¼kler.
        
        NEDEN BU MOD Ã–NCELÄ°KLÄ°?
          - Notebook zaten ÅŸunlarÄ± yapmÄ±ÅŸ:
            1. TotalCharges temizliÄŸi (business logic ile)
            2. 10 yeni feature Ã¼retimi (LoyaltyIndex, RiskScope vb.)
            3. ColumnTransformer ile preprocessing (scaling + encoding)
            4. PCA analizi
          - Yani X_mat = tam hazÄ±r, modele direkt girebilecek matris.
          - Bu, tekrarlanabilirliÄŸi artÄ±rÄ±r ve processing sÃ¼resini azaltÄ±r.
        
        Returns:
            (X_train, X_test, y_train, y_test) tuple'Ä±
        """
        logging.info(f"ðŸ“¦ Notebook artifact'Ä±ndan veri yÃ¼kleniyor: {self.config.npz_path}")

        # .npz dosyasÄ±nÄ± yÃ¼kle â€” iÃ§inde X_mat, y, X_pca_95 var
        npz_data = load_npz(self.config.npz_path)

        # Notebook'un export ettiÄŸi key'leri kontrol et
        required_keys = ["X", "y"]
        for key in required_keys:
            if key not in npz_data:
                raise KeyError(
                    f"NPZ dosyasÄ±nda '{key}' key'i bulunamadÄ±. "
                    f"Mevcut key'ler: {list(npz_data.keys())}"
                )

        X = npz_data["X"]   # (7043, N) â€” preprocessed feature matrisi
        y = npz_data["y"]   # (7043,) â€” hedef vektÃ¶rÃ¼ (0/1)

        logging.info(f"  X shape: {X.shape} | y shape: {y.shape}")
        logging.info(f"  Churn oranÄ±: {y.mean():.4f} ({y.sum():.0f}/{len(y)})")

        # Train / Test bÃ¶lmesi
        # NEDEN STRATÄ°FY?
        #   Churn dengesiz (~%27). Stratify olmadan test setinde churn oranÄ±
        #   %15 veya %40 olabilir â†’ metrikler yanÄ±ltÄ±cÄ± olur.
        #   stratify=y ile her iki sette de ~%27 oranÄ± korunur.
        X_train, X_test, y_train, y_test = train_test_split(
            X, y,
            test_size=self.config.test_size,
            random_state=self.config.random_state,
            stratify=y if self.config.stratify else None
        )

        logging.info(
            f"  Train/Test bÃ¶lÃ¼ndÃ¼ â†’ "
            f"Train: {X_train.shape[0]} satÄ±r | Test: {X_test.shape[0]} satÄ±r"
        )

        return X_train, X_test, y_train, y_test

    def _load_from_raw_csv(self) -> tuple:
        """
        MOD 2: Ham CSV'den okur. Notebook Ã§alÄ±ÅŸtÄ±rÄ±lmamÄ±ÅŸsa fallback.
        
        DÄ°KKAT:
          - Bu modda veri HAM haliyle gelir (cleaning/FE yapÄ±lmamÄ±ÅŸ).
          - data_transformation.py'nin tÃ¼m iÅŸleri Ã¼stlenmesi gerekir.
          - Bu mod DataFrame dÃ¶ndÃ¼rÃ¼r (numpy array deÄŸil).
        
        Returns:
            (train_df, test_df) tuple'Ä± â€” pandas DataFrame
        """
        logging.info(f"ðŸ“‚ Ham CSV'den veri yÃ¼kleniyor: {self.config.raw_data_path}")

        if not os.path.exists(self.config.raw_data_path):
            raise FileNotFoundError(
                f"Ham veri dosyasÄ± bulunamadÄ±: {self.config.raw_data_path}\n"
                f"LÃ¼tfen data/raw/ klasÃ¶rÃ¼ne churn.csv dosyasÄ±nÄ± yerleÅŸtirin."
            )

        df = pd.read_csv(self.config.raw_data_path)
        logging.info(f"  Veri seti okundu: {df.shape[0]} satÄ±r Ã— {df.shape[1]} sÃ¼tun")

        # Hedef deÄŸiÅŸkeni 0/1'e Ã§evir (Yes/No â†’ 1/0)
        if self.config.target_col in df.columns:
            if df[self.config.target_col].dtype == "object":
                df[self.config.target_col] = df[self.config.target_col].map(
                    {"Yes": 1, "No": 0}
                ).astype(int)
                logging.info(f"  '{self.config.target_col}' sÃ¼tunu Yes/No â†’ 1/0 olarak dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼")

        # Train / Test bÃ¶lmesi
        train_df, test_df = train_test_split(
            df,
            test_size=self.config.test_size,
            random_state=self.config.random_state,
            stratify=df[self.config.target_col] if self.config.stratify else None
        )

        logging.info(
            f"  Train/Test bÃ¶lÃ¼ndÃ¼ â†’ "
            f"Train: {train_df.shape[0]} satÄ±r | Test: {test_df.shape[0]} satÄ±r"
        )

        return train_df, test_df

    def initiate(self) -> tuple:
        """
        Veri alma sÃ¼recini baÅŸlatÄ±r. Ã–nce notebook artifact'Ä±nÄ± dener,
        yoksa ham CSV'ye dÃ¼ÅŸer.
        
        KARAR MANTIÄžI:
          1. notebooks/artifacts/telco_prepared_dataset.npz var mÄ±? â†’ Mod 1
          2. Yoksa â†’ data/raw/churn.csv'den oku â†’ Mod 2
        
        Returns:
            MOD 1: (X_train, X_test, y_train, y_test) â€” numpy array'ler
            MOD 2: (train_df, test_df) â€” pandas DataFrame'ler
        """
        try:
            logging.info("=" * 60)
            logging.info("DATA INGESTION baÅŸlatÄ±lÄ±yor...")
            logging.info("=" * 60)

            # Artifacts klasÃ¶rÃ¼nÃ¼ oluÅŸtur (yoksa)
            os.makedirs(self.config.artifacts_dir, exist_ok=True)

            # Karar: NPZ var mÄ±?
            if os.path.exists(self.config.npz_path):
                logging.info("âœ… Notebook artifact bulundu â†’ Mod 1 (NPZ Bridge)")
                result = self._load_from_notebook_npz()
                mode = "npz"
            else:
                logging.info("âš  Notebook artifact bulunamadÄ± â†’ Mod 2 (Raw CSV Fallback)")
                result = self._load_from_raw_csv()
                mode = "csv"

            logging.info(f"DATA INGESTION tamamlandÄ± (mod: {mode})")
            logging.info("=" * 60)

            return result

        except Exception as e:
            raise CustomException(e, sys)

