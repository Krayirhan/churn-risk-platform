# ============================================================================
# model_monitor.py ‚Äî Model Performans ƒ∞zleme Bile≈üeni
# ============================================================================
# NEDEN BU DOSYA VAR?
#   Model production'a √ßƒ±ktƒ±ktan sonra performansƒ± zamanla d√º≈üebilir
#   (model decay / concept drift). Bu mod√ºl:
#     1. Baseline metriklerle g√ºncel durumu kar≈üƒ±la≈ütƒ±rƒ±r
#     2. Drift analizi sonu√ßlarƒ±nƒ± birle≈ütirir
#     3. Retrain kararƒ± verir (gerekli mi, deƒüil mi?)
#     4. Monitoring raporu √ºretir
#
# KAVRAM ‚Äî MODEL DECAY:
#   M√º≈üteri davranƒ±≈üƒ± zamanla deƒüi≈üir. 2020'de eƒüitilen model 2026'da
#   artƒ±k ge√ßersiz olabilir √ß√ºnk√º:
#     - Yeni tarifeler √ßƒ±kmƒ±≈ü (MonthlyCharges daƒüƒ±lƒ±mƒ± deƒüi≈ümi≈ü)
#     - Fiber optic artƒ±k varsayƒ±lan olmu≈ü (InternetService daƒüƒ±lƒ±mƒ±)
#     - Pandemi sonrasƒ± s√∂zle≈üme tercihleri farklƒ±la≈ümƒ±≈ü
#
# √áAƒûRILI≈û:
#   monitor = ModelMonitor()
#   report = monitor.full_check()
#   print(report["needs_retrain"])  # True / False
# ============================================================================

import os
import sys
from datetime import datetime
from dataclasses import dataclass, field
from typing import Optional

from src.exception import CustomException
from src.logger import logging
from src.utils.common import load_yaml, load_json, save_json


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# KONFƒ∞G√úRASYON
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

@dataclass
class ModelMonitorConfig:
    """
    Performans izleme ayarlarƒ±. monitoring.yaml'dan okunur.
    """
    _mon: dict = field(default=None, repr=False)

    def __post_init__(self):
        self._mon = load_yaml("configs/monitoring.yaml")
        perf_cfg = self._mon.get("performance", {})
        retrain_cfg = self._mon.get("retrain", {})

        self.enabled: bool = perf_cfg.get("enabled", True)
        self.baseline_path: str = perf_cfg.get(
            "baseline_metrics_path", "artifacts/metrics.json"
        )
        self.degradation_thresholds: dict = perf_cfg.get(
            "degradation_thresholds",
            {"f1": 0.10, "recall": 0.15, "precision": 0.10, "roc_auc": 0.05},
        )

        # Retrain ayarlarƒ±
        self.auto_retrain: bool = retrain_cfg.get("auto_retrain", False)
        self.cooldown_hours: int = retrain_cfg.get("cooldown_hours", 24)
        self.history_path: str = retrain_cfg.get(
            "history_path", "logs/retrain_history.json"
        )


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ANA SINIF
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

class ModelMonitor:
    """
    Model performansƒ±nƒ± izler, drift sonu√ßlarƒ±yla birle≈ütirir
    ve retrain gerekip gerekmediƒüine karar verir.

    KULLANIM:
        monitor = ModelMonitor()

        # Sadece performans kontrol√º
        perf_report = monitor.check_performance(current_metrics)

        # Tam kontrol (performans + drift)
        full_report = monitor.full_check(current_metrics, drift_report)
    """

    def __init__(self, config: Optional[ModelMonitorConfig] = None):
        try:
            self.config = config or ModelMonitorConfig()
        except Exception as e:
            raise CustomException(e, sys)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # BASELINE METRƒ∞KLER
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    def get_baseline(self) -> dict:
        """
        Eƒüitim sonrasƒ± kaydedilen baseline metrikleri y√ºkler.

        Returns:
            dict: {"accuracy": 0.79, "f1": 0.61, "recall": 0.52, ...}
        """
        try:
            if not os.path.exists(self.config.baseline_path):
                raise FileNotFoundError(
                    f"Baseline metrikleri bulunamadƒ±: {self.config.baseline_path}"
                )
            data = load_json(self.config.baseline_path)
            return data.get("metrics", data)
        except Exception as e:
            raise CustomException(e, sys)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # PERFORMANS KONTROL√ú
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    def check_performance(self, current_metrics: dict) -> dict:
        """
        G√ºncel metrikleri baseline ile kar≈üƒ±la≈ütƒ±rƒ±r.

        AKI≈û:
          1. Baseline metrikleri y√ºkle (eƒüitim sonrasƒ± kaydedilmi≈ü)
          2. Her metrik i√ßin: (baseline - current) / baseline > threshold?
          3. Degraded metrikleri listele
          4. Genel performance_ok kararƒ± ver

        Args:
            current_metrics: G√ºncel model metrikleri
                {"f1": 0.55, "recall": 0.48, ...}

        Returns:
            dict: {
                "performance_ok": bool,
                "degraded_metrics": [...],
                "comparisons": {metrik: {baseline, current, drop, threshold}},
                "status": "healthy" | "degraded" | "critical"
            }
        """
        try:
            logging.info("üìà Performans kontrol√º yapƒ±lƒ±yor...")

            baseline = self.get_baseline()
            degraded = []
            comparisons = {}

            for metric, threshold in self.config.degradation_thresholds.items():
                base_val = baseline.get(metric)
                curr_val = current_metrics.get(metric)

                if base_val is None or curr_val is None:
                    continue

                # Y√ºzde d√º≈ü√º≈ü hesapla
                drop = (base_val - curr_val) / base_val if base_val > 0 else 0.0
                is_degraded = drop > threshold

                comparisons[metric] = {
                    "baseline": round(base_val, 4),
                    "current": round(curr_val, 4),
                    "drop_pct": round(drop * 100, 2),
                    "threshold_pct": round(threshold * 100, 2),
                    "degraded": is_degraded,
                }

                if is_degraded:
                    degraded.append(metric)
                    logging.warning(
                        f"  ‚ö† {metric}: {base_val:.4f} ‚Üí {curr_val:.4f} "
                        f"(d√º≈ü√º≈ü: %{drop*100:.1f}, e≈üik: %{threshold*100:.0f})"
                    )
                else:
                    logging.info(
                        f"  ‚úÖ {metric}: {base_val:.4f} ‚Üí {curr_val:.4f} "
                        f"(d√º≈ü√º≈ü: %{drop*100:.1f})"
                    )

            # Genel durum
            if len(degraded) == 0:
                status = "healthy"
            elif len(degraded) <= 1:
                status = "degraded"
            else:
                status = "critical"

            result = {
                "performance_ok": len(degraded) == 0,
                "degraded_metrics": degraded,
                "total_checked": len(comparisons),
                "comparisons": comparisons,
                "status": status,
            }

            logging.info(
                f"  Performans durumu: {status} "
                f"({len(degraded)} metrik bozulmu≈ü)"
            )

            return result

        except Exception as e:
            raise CustomException(e, sys)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # TAM KONTROL ‚Äî Performans + Drift Birle≈ütirme
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    def full_check(
        self,
        current_metrics: Optional[dict] = None,
        drift_report: Optional[dict] = None,
    ) -> dict:
        """
        Performans ve drift sonu√ßlarƒ±nƒ± birle≈ütirerek retrain kararƒ± verir.

        KARAR MATRƒ∞Sƒ∞:
          - Drift YOK + Performans OK     ‚Üí ‚úÖ "stable" (retrain gereksiz)
          - Drift YOK + Performans D√ú≈ûT√ú  ‚Üí ‚ö† "degraded" (izle)
          - Drift VAR + Performans OK     ‚Üí ‚ö† "drift_warning" (izle)
          - Drift VAR + Performans D√ú≈ûT√ú  ‚Üí üö® "retrain_needed" (acil)

        Args:
            current_metrics: G√ºncel model metrikleri (opsiyonel)
            drift_report: DriftDetector.analyze() √ßƒ±ktƒ±sƒ± (opsiyonel)

        Returns:
            dict: Birle≈üik monitoring raporu
        """
        try:
            logging.info("üîé Tam monitoring kontrol√º ba≈ülatƒ±lƒ±yor...")

            report = {
                "timestamp": datetime.now().isoformat(),
                "needs_retrain": False,
                "retrain_reason": [],
                "overall_status": "stable",
                "performance": None,
                "drift": None,
            }

            # ‚îÄ‚îÄ‚îÄ Performans kontrol√º ‚îÄ‚îÄ‚îÄ
            has_perf_issue = False
            if current_metrics:
                perf_result = self.check_performance(current_metrics)
                report["performance"] = perf_result
                if not perf_result["performance_ok"]:
                    has_perf_issue = True
                    report["retrain_reason"].append("performance_degraded")

            # ‚îÄ‚îÄ‚îÄ Drift kontrol√º ‚îÄ‚îÄ‚îÄ
            has_drift = False
            if drift_report:
                report["drift"] = {
                    "drift_detected": drift_report.get("drift_detected", False),
                    "drift_ratio": drift_report.get("drift_ratio", 0),
                    "drifted_features": drift_report.get("drifted_features", []),
                    "alert_level": drift_report.get("alert_level", "none"),
                }
                if drift_report.get("drift_detected", False):
                    has_drift = True
                    report["retrain_reason"].append("drift_detected")

            # ‚îÄ‚îÄ‚îÄ Genel karar ‚îÄ‚îÄ‚îÄ
            if has_drift and has_perf_issue:
                report["overall_status"] = "retrain_needed"
                report["needs_retrain"] = True
            elif has_perf_issue:
                report["overall_status"] = "degraded"
                report["needs_retrain"] = True
            elif has_drift:
                report["overall_status"] = "drift_warning"
                # Drift var ama performans d√º≈ümemi≈ü ‚Üí hemen retrain gerekmez
                report["needs_retrain"] = False
            else:
                report["overall_status"] = "stable"

            status_emoji = {
                "stable": "‚úÖ",
                "degraded": "‚ö†Ô∏è",
                "drift_warning": "üîÑ",
                "retrain_needed": "üö®",
            }
            logging.info(
                f"  {status_emoji.get(report['overall_status'], '‚ùì')} "
                f"Genel durum: {report['overall_status']} | "
                f"Retrain: {'EVET' if report['needs_retrain'] else 'HAYIR'}"
            )

            return report

        except Exception as e:
            raise CustomException(e, sys)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # RETRAƒ∞N GE√áMƒ∞≈ûƒ∞
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    def log_retrain_event(self, reason: str, result: dict) -> None:
        """
        Retrain olayƒ±nƒ± ge√ßmi≈ü dosyasƒ±na kaydeder.

        Args:
            reason: Retrain nedeni ("drift_detected", "performance_degraded", "manual")
            result: TrainPipeline.run() √ßƒ±ktƒ±sƒ±
        """
        try:
            history = []
            if os.path.exists(self.config.history_path):
                history = load_json(self.config.history_path)
                if not isinstance(history, list):
                    history = []

            event = {
                "timestamp": datetime.now().isoformat(),
                "reason": reason,
                "best_model": result.get("best_model", "unknown"),
                "best_f1": result.get("best_f1", 0),
                "total_time": result.get("total_time", "N/A"),
            }
            history.append(event)

            save_json(history, self.config.history_path)
            logging.info(f"üìù Retrain olayƒ± kaydedildi: {reason}")

        except Exception as e:
            logging.error(f"Retrain ge√ßmi≈üi kayƒ±t hatasƒ±: {e}")

    def get_retrain_history(self) -> list:
        """
        Retrain ge√ßmi≈üini d√∂nd√ºr√ºr.

        Returns:
            list: Retrain olaylarƒ±nƒ±n listesi
        """
        try:
            if not os.path.exists(self.config.history_path):
                return []
            data = load_json(self.config.history_path)
            return data if isinstance(data, list) else []
        except Exception:
            return []

    def can_retrain(self) -> bool:
        """
        Cooldown s√ºresi ge√ßmi≈ü mi kontrol eder.

        Son retrain'den bu yana yeterli s√ºre (cooldown_hours) ge√ßmediyse
        yeni retrain engellenebilir (√ßok sƒ±k eƒüitim √∂nlenir).

        Returns:
            bool: True ‚Üí retrain yapƒ±labilir
        """
        try:
            history = self.get_retrain_history()
            if not history:
                return True

            last_event = history[-1]
            last_time = datetime.fromisoformat(last_event["timestamp"])
            hours_since = (datetime.now() - last_time).total_seconds() / 3600

            can = hours_since >= self.config.cooldown_hours
            if not can:
                logging.info(
                    f"  ‚è≥ Cooldown aktif: Son retrain {hours_since:.1f}h √∂nce "
                    f"(minimum {self.config.cooldown_hours}h)"
                )
            return can

        except Exception:
            return True
