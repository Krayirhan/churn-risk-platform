# ============================================================================
# train_pipeline.py â€” UÃ§tan Uca EÄŸitim Boru HattÄ±
# ============================================================================
# NEDEN BU DOSYA VAR?
#   TÃ¼m bileÅŸenleri (Ingestion â†’ Transformation â†’ Training â†’ Evaluation)
#   tek bir run() Ã§aÄŸrÄ±sÄ±yla zincirler. Tekil bileÅŸenler birbirinden
#   baÄŸÄ±msÄ±z Ã§alÄ±ÅŸabilir ama production'da pipeline olarak Ã§alÄ±ÅŸÄ±r.
#
# VERÄ° AKIÅI:
#   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#   â”‚ Ingestion  â”‚â”€â”€â–¶â”‚ Transformation   â”‚â”€â”€â–¶â”‚   Trainer    â”‚â”€â”€â–¶â”‚  Evaluation    â”‚
#   â”‚ (NPZ/CSV)  â”‚   â”‚ (Clean+FE+Scale) â”‚   â”‚ (GridSearch) â”‚   â”‚ (Metrik+Rapor) â”‚
#   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#        â†“ Mod1â†’numpy     â†“ numpy             â†“ model.pkl       â†“ metrics.json
#        â†“ Mod2â†’DataFrame â†“ numpy             â†“ best_f1         â†“ confusion_matrix.json
#
# Ã‡AÄRILIÅ ÅEKLÄ°:
#   python main.py --train
#   veya: from src.pipeline.train_pipeline import TrainPipeline; TrainPipeline().run()
# ============================================================================

import sys
import time
import numpy as np

from src.exception import CustomException
from src.logger import logging


class TrainPipeline:
    """
    UÃ§tan uca model eÄŸitim boru hattÄ±nÄ± yÃ¶neten sÄ±nÄ±f.

    Neden ayrÄ± bir pipeline sÄ±nÄ±fÄ±?
      - BileÅŸenler (Ingestion, Transformation, Trainer, Evaluation) kendi baÅŸlarÄ±na
        unit-test edilebilir (loose coupling).
      - Pipeline bunlarÄ± doÄŸru sÄ±rada Ã§aÄŸÄ±rÄ±r ve hata yÃ¶netimini merkezileÅŸtirir.
      - Her adÄ±mÄ±n sÃ¼resini Ã¶lÃ§er ve hangi adÄ±mda kÄ±rÄ±ldÄ±ÄŸÄ±nÄ± raporlar.

    KullanÄ±m:
        pipeline = TrainPipeline()
        result = pipeline.run()
        print(result["best_f1"])        # â†’ 0.6123
        print(result["best_model"])     # â†’ "XGBClassifier"
        print(result["timings"])        # â†’ {"ingestion": 1.2, "transformation": 3.5, ...}
    """

    def __init__(self):
        # BileÅŸenleri lazy-import ediyoruz (import dÃ¶ngÃ¼sÃ¼ riskini Ã¶nler)
        # __init__'te sadece boÅŸ state tutuyoruz; run() iÃ§inde oluÅŸturulacak
        self.timings: dict = {}

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ADIM 1: Veri Alma (Data Ingestion)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _step_ingestion(self) -> tuple:
        """
        DataIngestion bileÅŸenini Ã§alÄ±ÅŸtÄ±rÄ±r.

        Ä°ki farklÄ± sonuÃ§ dÃ¶ner:
          - Mod 1 (NPZ): (X_train, X_test, y_train, y_test) â†’ numpy
          - Mod 2 (CSV): (train_df, test_df) â†’ pandas DataFrame

        Returns:
            tuple: Ingestion sonucu (mod'a gÃ¶re farklÄ± tiplerde)
        """
        from src.components.data_ingestion import DataIngestion

        logging.info("ğŸ”· ADIM 1/4 â€” DATA INGESTION")
        t0 = time.time()

        ingestion = DataIngestion()
        result = ingestion.initiate()

        elapsed = round(time.time() - t0, 2)
        self.timings["ingestion"] = elapsed
        logging.info(f"  â± Ingestion sÃ¼resi: {elapsed}s")

        return result

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ADIM 2: Veri DÃ¶nÃ¼ÅŸtÃ¼rme (Data Transformation) â€” Sadece CSV modunda
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _step_transformation(self, train_df, test_df) -> tuple:
        """
        DataTransformation bileÅŸenini Ã§alÄ±ÅŸtÄ±rÄ±r.

        SADECE CSV MODUNDA Ã‡AÄRILIR!
        NPZ modunda notebook zaten tÃ¼m dÃ¶nÃ¼ÅŸÃ¼mleri yapmÄ±ÅŸ â†’ bu adÄ±m atlanÄ±r.

        Args:
            train_df: EÄŸitim DataFrame'i
            test_df: Test DataFrame'i

        Returns:
            (X_train, X_test, y_train, y_test, preprocessor_path)
        """
        from src.components.data_transformation import DataTransformation

        logging.info("ğŸ”· ADIM 2/4 â€” DATA TRANSFORMATION")
        t0 = time.time()

        transformation = DataTransformation()
        X_train, X_test, y_train, y_test, pp_path = transformation.initiate(
            train_df, test_df
        )

        elapsed = round(time.time() - t0, 2)
        self.timings["transformation"] = elapsed
        logging.info(f"  â± Transformation sÃ¼resi: {elapsed}s")
        logging.info(f"  ğŸ“¦ Preprocessor kaydedildi â†’ {pp_path}")

        return X_train, X_test, y_train, y_test

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ADIM 3: Model EÄŸitimi (Model Training)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _step_training(
        self,
        X_train: np.ndarray,
        X_test: np.ndarray,
        y_train: np.ndarray,
        y_test: np.ndarray,
    ) -> tuple:
        """
        ModelTrainer bileÅŸenini Ã§alÄ±ÅŸtÄ±rÄ±r.

        4 modeli GridSearchCV ile eÄŸitir, F1 bazÄ±nda en iyisini seÃ§er ve kaydeder.

        Returns:
            (best_f1, full_report)
        """
        from src.components.model_trainer import ModelTrainer

        logging.info("ğŸ”· ADIM 3/4 â€” MODEL TRAINING")
        t0 = time.time()

        trainer = ModelTrainer()
        best_f1, report = trainer.initiate(X_train, X_test, y_train, y_test)

        elapsed = round(time.time() - t0, 2)
        self.timings["training"] = elapsed
        logging.info(f"  â± Training sÃ¼resi: {elapsed}s")

        return best_f1, report

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ADIM 4: Model DeÄŸerlendirme (Model Evaluation)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _step_evaluation(
        self,
        X_test: np.ndarray,
        y_test: np.ndarray,
        model_name: str,
    ) -> dict:
        """
        ModelEvaluation bileÅŸenini Ã§alÄ±ÅŸtÄ±rÄ±r.

        Confusion matrix, ROC-AUC, PR-AUC hesaplar ve JSON olarak kaydeder.

        Returns:
            dict: DetaylÄ± deÄŸerlendirme raporu
        """
        from src.components.model_evaluation import ModelEvaluation

        logging.info("ğŸ”· ADIM 4/4 â€” MODEL EVALUATION")
        t0 = time.time()

        evaluator = ModelEvaluation()
        eval_result = evaluator.initiate(
            model=None,  # artifacts/model.pkl'den otomatik yÃ¼kler
            X_test=X_test,
            y_test=y_test,
            model_name=model_name,
        )

        elapsed = round(time.time() - t0, 2)
        self.timings["evaluation"] = elapsed
        logging.info(f"  â± Evaluation sÃ¼resi: {elapsed}s")

        return eval_result

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ANA Ã‡ALIÅTIRICI
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def run(self) -> dict:
        """
        TÃ¼m pipeline'Ä± sÄ±rasÄ±yla Ã§alÄ±ÅŸtÄ±rÄ±r.

        AKIÅ:
          1. Ingestion  â†’ Veriyi al (NPZ veya CSV)
          2. Transform  â†’ Sadece CSV modundaysa Ã§alÄ±ÅŸÄ±r
          3. Training   â†’ GridSearchCV ile en iyi modeli bul
          4. Evaluation â†’ DetaylÄ± rapor Ã¼ret

        Returns:
            dict: {
                "best_model": str,
                "best_f1": float,
                "eval_result": dict,
                "training_report": dict,
                "timings": dict,
                "mode": "npz" | "csv",
                "total_time": float
            }

        Raises:
            CustomException: Herhangi bir adÄ±mda hata olursa,
                             hatanÄ±n hangi adÄ±mda oluÅŸtuÄŸu belirtilir.
        """
        pipeline_start = time.time()
        current_step = "baÅŸlatma"

        try:
            logging.info("â•”" + "â•" * 58 + "â•—")
            logging.info("â•‘        TRAIN PIPELINE BAÅLATILIYOR                       â•‘")
            logging.info("â•š" + "â•" * 58 + "â•")

            # â”€â”€â”€ ADIM 1: Ingestion â”€â”€â”€
            current_step = "ingestion"
            ingestion_result = self._step_ingestion()

            # â”€â”€â”€ MOD TESPÄ°TÄ° â”€â”€â”€
            # Ingestion'Ä±n dÃ¶ndÃ¼ÄŸÃ¼ ilk elemanÄ±n tipine gÃ¶re mod belirlenir:
            #   numpy.ndarray â†’ Mod 1 (NPZ): Zaten preprocessed, transformation atlanÄ±r
            #   pd.DataFrame  â†’ Mod 2 (CSV): Ham veri, transformation gerekli
            if isinstance(ingestion_result[0], np.ndarray):
                mode = "npz"
                X_train, X_test, y_train, y_test = ingestion_result
                self.timings["transformation"] = 0.0  # NPZ'de atlandÄ±
                logging.info("  ğŸ“Œ Mod 1 (NPZ) tespit edildi â†’ Transformation atlanÄ±yor")
            else:
                mode = "csv"
                train_df, test_df = ingestion_result

                # â”€â”€â”€ ADIM 2: Transformation (sadece CSV modunda) â”€â”€â”€
                current_step = "transformation"
                X_train, X_test, y_train, y_test = self._step_transformation(
                    train_df, test_df
                )

            # â”€â”€â”€ ADIM 3: Training â”€â”€â”€
            current_step = "training"
            best_f1, training_report = self._step_training(
                X_train, X_test, y_train, y_test
            )

            best_model_name = training_report.get("best_model", "unknown")

            # â”€â”€â”€ ADIM 4: Evaluation â”€â”€â”€
            current_step = "evaluation"
            eval_result = self._step_evaluation(
                X_test, y_test, best_model_name
            )

            # â”€â”€â”€ SONUÃ‡ Ã–ZETÄ° â”€â”€â”€
            total_time = round(time.time() - pipeline_start, 2)
            self.timings["total"] = total_time

            logging.info("")
            logging.info("â•”" + "â•" * 58 + "â•—")
            logging.info("â•‘        TRAIN PIPELINE TAMAMLANDI âœ…                      â•‘")
            logging.info("â•š" + "â•" * 58 + "â•")
            logging.info(f"  Mod            : {mode.upper()}")
            logging.info(f"  En iyi model   : {best_model_name}")
            logging.info(f"  Best F1        : {best_f1:.4f}")
            logging.info(f"  Toplam sÃ¼re    : {total_time}s")
            logging.info(f"  AdÄ±m sÃ¼releri  : {self.timings}")

            result = {
                "best_model": best_model_name,
                "best_f1": best_f1,
                "eval_result": eval_result,
                "training_report": training_report,
                "timings": self.timings,
                "mode": mode,
                "total_time": total_time,
            }

            return result

        except Exception as e:
            total_time = round(time.time() - pipeline_start, 2)
            logging.error(
                f"âŒ Pipeline '{current_step}' adÄ±mÄ±nda baÅŸarÄ±sÄ±z oldu! ({total_time}s)"
            )
            raise CustomException(e, sys)
